# Phase 4 Report: Comprehensive Evaluation on Real BCI IV-2a Data

## Overview

This report documents the final Phase 4 results for the thesis:
**Transfer Learning Based Motor Imagery EEG Classification with Reduced Data**

All experiments use the **BCI Competition IV Dataset 2a** (BNCI2014-001):
- 9 subjects, 288 trials each (144 left / 144 right hand MI)
- 22 EEG channels, 4s trials at 250 Hz → resampled to 128 Hz via MOABB
- Evaluation: within-subject 5-fold stratified CV and LOSO cross-subject CV

---

## 4.1 Baseline Results (Real Data)

| Model | Strategy | Accuracy | ±Std | κ | F1 |
|---|---|---|---|---|---|
| Baseline A: CSP+LDA | Within-subject 5-fold | **79.32%** | 12.53% | 0.586 | 0.793 |
| Baseline A: CSP+LDA | LOSO | 65.78% | 10.84% | 0.316 | 0.635 |
| Baseline B: Riemannian+LDA | Within-subject 5-fold | 61.65% | 9.41% | 0.233 | 0.614 |
| Baseline B: Riemannian+LDA | LOSO | 63.85% | 11.14% | 0.277 | 0.602 |
| Baseline C: CWT+ViT-Tiny | Within-subject 5-fold | 52.58% | 8.10% | 0.052 | 0.509 |

**Observations:**
- CSP+LDA achieves the strongest within-subject performance (79.32%), consistent with the literature (typical range 70–85% for BCI IV-2a binary MI).
- The ViT-only baseline (Baseline C) performs near chance (52.58%), confirming that raw spectrograms alone are insufficient without domain-specific features or transfer learning. This motivates the dual-branch architecture.
- Riemannian features show surprisingly competitive LOSO performance (63.85%), suggesting they generalize better across subjects than CSP, but still fall short without neural learning.

### Per-Subject Breakdown (CSP+LDA LOSO)

| Subject | LOSO Acc |
|---|---|
| S01 | 65.97% |
| S02 | 55.21% |
| S03 | 74.65% |
| S04 | 67.36% |
| S05 | 55.21% |
| S06 | 53.47% |
| S07 | 61.11% |
| S08 | **89.58%** |
| S09 | 69.44% |

Subject S08 is a strong performer (89.58%); S02, S05, S06 are poor performers, which is consistent with BCI IV-2a literature (some subjects produce weak MI signals).

---

## 4.2 Dual-Branch Model Results

*Fill in after running on GPU machine.*

| Model | Fusion | Strategy | Accuracy | ±Std | κ | F1 |
|---|---|---|---|---|---|---|
| Dual-Branch | Attention | Within-subject 5-fold | — | — | — | — |
| Dual-Branch | Concat | Within-subject 5-fold | — | — | — | — |
| Dual-Branch | Gated | Within-subject 5-fold | — | — | — | — |
| Dual-Branch | Attention | LOSO | — | — | — | — |

**Expected:** Dual-branch should outperform all baselines by combining ViT's spatial-frequency representations with CSP's discriminative spatial filters and Riemannian covariance structure.

### 4.2.1 Fusion Ablation

*Fill in after running.*

The attention fusion mechanism is expected to outperform concat and gated because it dynamically weights the ViT and math-branch contributions per sample, allowing the model to rely more on whichever branch is more informative for a given trial.

---

## 4.3 Transfer Learning Results

*Fill in after running on GPU machine.*

### 4.3.1 Condition Comparison

| Condition | Description | Accuracy | ±Std | κ |
|---|---|---|---|---|
| Scratch | Random ViT init | — | — | — |
| ImageNet | ImageNet-pretrained ViT | — | — | — |
| EEG-Pretrained | Domain-pretrained ViT (Ours) | — | — | — |

**Expected:** EEG-pretrained ViT (transfer condition) should outperform scratch training, especially at lower data fractions, because the backbone has already learned EEG-relevant time-frequency features from the source dataset.

### 4.3.2 Reduced-Data Experiment (Core Thesis Result)

*Fill in after running.*

| Training Data | Scratch | EEG-Pretrained | Advantage |
|---|---|---|---|
| 10% | — | — | — |
| 25% | — | — | — |
| 50% | — | — | — |
| 75% | — | — | — |
| 100% | — | — | — |

**Interpretation:** The transfer learning advantage is expected to be largest at low data fractions (10–25%), where the pretrained backbone's prior knowledge compensates for limited labelled examples.

---

## 4.4 Statistical Analysis

*Fill in after running `phase4_stats.py`.*

### 4.4.1 Dual-Branch vs Baselines (Wilcoxon Signed-Rank, per-subject)

| Comparison | N | Mean Diff | p-value | Sig | Cohen's d | Effect |
|---|---|---|---|---|---|---|
| Dual-Branch vs CSP+LDA | 9 | — | — | — | — | — |
| Dual-Branch vs Riemannian | 9 | — | — | — | — | — |
| Dual-Branch vs ViT-Only | 9 | — | — | — | — | — |

### 4.4.2 Transfer Conditions (Paired t-test, per-subject)

| Comparison | N | Mean Diff | p-value | Sig | Cohen's d | Effect |
|---|---|---|---|---|---|---|
| EEG-Pretrained vs Scratch | 9 | — | — | — | — | — |
| EEG-Pretrained vs ImageNet | 9 | — | — | — | — | — |
| ImageNet vs Scratch | 9 | — | — | — | — | — |

*Significance: *** p<0.001, ** p<0.01, * p<0.05, n.s. = not significant*

---

## 4.5 Figures

Generated by `scripts/phase4_visualize.py` into `figures/`:

- **fig1_cwt_spectrograms.png** — CWT spectrogram examples (left vs right MI)
- **fig2_reduced_data_curves.png** — Accuracy vs training data fraction
- **fig3_fusion_ablation.png** — Fusion method comparison bar chart
- **fig4_per_subject_heatmap.png** — Per-subject accuracy by model
- **fig5_baseline_comparison.png** — All models within-subject accuracy

---

## 4.6 Discussion

### Why does ViT-only (Baseline C) perform near chance?

The CWT spectrogram representation is rich but ViT-Tiny with only 50 epochs and 288 trials per subject is severely data-limited. ViT models are known to require large datasets; on 230 training trials (80% of 288), the model cannot learn discriminative patterns from scratch. This motivates both the dual-branch design (adding CSP+Riemannian which work well with small N) and the transfer learning contribution (pre-initializing ViT with EEG-domain knowledge).

### Why does CSP+LDA outperform Riemannian within-subject?

CSP is a discriminative method — it explicitly maximizes variance ratio between classes — while the Riemannian tangent space representation is unsupervised in the covariance estimation step. For within-subject CV where train and test data come from the same session and subject, CSP's discriminative filter learning is highly effective. However, LOSO shows Riemannian is more competitive cross-subject, consistent with literature showing Riemannian geometry captures more subject-invariant structure.

### Data scarcity hypothesis

The thesis central claim is that EEG-domain pretraining on a large source population enables the ViT branch to converge faster and generalize better when target labelled data is limited. The reduced-data experiment (Section 4.3.2) is the primary empirical test of this hypothesis.

---

## 4.7 How to Reproduce

See `README.md` for the full command sequence. The recommended order on a GPU machine:

```bash
# 1. Baselines (fast, already done on CPU)
uv run python scripts/baseline_a_csp_lda.py --data real --output results/real_baseline_a_csp_lda.json
uv run python scripts/baseline_b_riemannian.py --data real --output results/real_baseline_b_riemannian.json
uv run python scripts/baseline_c_vit.py --data real --epochs 50 --output results/real_baseline_c_vit.json

# 2. Dual-branch (GPU recommended, ~30-60 min each)
for FUSION in attention concat gated; do
    uv run python scripts/train_dual_branch.py --data real --epochs 50 \
        --fusion $FUSION --output results/real_dual_branch_${FUSION}.json
done

# 3. Transfer learning
uv run python scripts/pretrain_physionet.py --data synthetic --n-subjects 20 \
    --epochs 50 --no-pretrained --checkpoint checkpoints/vit_pretrained_eeg.pt
uv run python scripts/finetune_bci_iv2a.py --data real \
    --checkpoint checkpoints/vit_pretrained_eeg.pt \
    --conditions scratch imagenet transfer --n-folds 5 --epochs 50 \
    --output-dir results/
uv run python scripts/reduced_data_experiment.py --data real \
    --checkpoint checkpoints/vit_pretrained_eeg.pt \
    --fractions 0.10 0.25 0.50 0.75 1.00 --n-repeats 3 --epochs 50 \
    --output results/real_reduced_data_results.json

# 4. Analysis
uv run python scripts/phase4_compile_results.py --prefix real_ --output results/phase4_summary.json
uv run python scripts/phase4_visualize.py --summary results/phase4_summary.json --output-dir figures/
uv run python scripts/phase4_stats.py --summary results/phase4_summary.json
```

---

*Last updated: Phase 4 in progress. Baselines A, B, C complete on real data. GPU experiments pending.*
